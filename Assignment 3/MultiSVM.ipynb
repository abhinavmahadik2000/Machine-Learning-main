{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e115ec95",
   "metadata": {},
   "source": [
    "# Multi-class SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef0ee730",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from mlxtend.plotting.decision_regions import plot_decision_regions\n",
    "\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4456bacc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_kernel(x1, x2):\n",
    "    return x1.T @ x2\n",
    "\n",
    "def poly_kernel(x1, x2, d = 2, c = 0):\n",
    "    return (x1 @ x2.T + c)**d\n",
    "\n",
    "\n",
    "class multiclass_svm():\n",
    "    def __init__(self, kernel='linear', c=1.0, tol=1e-3, maxiter=1000):\n",
    "        self._kernel = kernel\n",
    "        self._tol = tol\n",
    "        self._maxiter = maxiter\n",
    "        self.eps = 0.001\n",
    "        \n",
    "        if self._kernel == 'linear':\n",
    "            self._k = linear_kernel\n",
    "        elif self._kernel == 'poly':\n",
    "            self._k = poly_kernel\n",
    "        \n",
    "        self._c = c\n",
    "        \n",
    "    def _init_params(self):\n",
    "        self._error_cache = np.zeros(self._data.shape[0])\n",
    "        self._alphas = np.ones(self._data.shape[0]) * .1\n",
    "        self._b = 0\n",
    "        \n",
    "        if self._kernel == 'linear':\n",
    "            self._weights = np.random.rand(self._data.shape[1])\n",
    "\n",
    "    def predict_score(self, x):\n",
    "        \"\"\"Predicts a raw score (not classification)\n",
    "        \n",
    "        Arguments\n",
    "            x, array (batch_size, n_features) - input samples.\n",
    "        \"\"\"\n",
    "        u = 0\n",
    "        if self._kernel == 'linear':\n",
    "            u = self._weights @ x.T - self._b\n",
    "        else:\n",
    "            for i in range(self._data.shape[0]):\n",
    "                u += self._targets[i] * self._alphas[i] * self._k(self._data[i], x)\n",
    "            u -= self._b\n",
    "        return u\n",
    "        \n",
    "    def predict(self, x):\n",
    "        \"\"\"Classifies input samples.\n",
    "        \n",
    "        Arguments\n",
    "            x, array (batch_size, n_features) - input samples.\n",
    "        \"\"\"\n",
    "        score = self.predict_score(x)\n",
    "\n",
    "        if type(score) is np.ndarray:\n",
    "            score[score < 0] = -1\n",
    "            score[score >= 0] = 1\n",
    "\n",
    "            return score\n",
    "        else:\n",
    "            return -1 if score < 0 else 1\n",
    "\n",
    "    def smo_step(self, i1, i2):\n",
    "        if i1 == i2:\n",
    "            return 0\n",
    "\n",
    "        x1 = self._data[i1]\n",
    "        x2 = self._data[i2]\n",
    "        y1 = self._targets[i1]\n",
    "        y2 = self._targets[i2]\n",
    "        alpha1 = self._alphas[i1]\n",
    "        alpha2 = self._alphas[i2]\n",
    "\n",
    "        # Compute errors for x1 and x2\n",
    "        e1 = self.predict_score(x1) - y1\n",
    "        e2 = self.predict_score(x2) - y2\n",
    "\n",
    "        s = y1 * y2\n",
    "\n",
    "        if s == 1:\n",
    "            L = max(0, alpha2 + alpha1 - self._c)\n",
    "            H = min(self._c, alpha2 + alpha1)\n",
    "        else:\n",
    "            L = max(0, alpha2 - alpha1)\n",
    "            H = min(self._c, self._c + alpha2 - alpha1)\n",
    "\n",
    "        if L == H:\n",
    "            return 0\n",
    "\n",
    "        k11 = self._k(x1, x1)\n",
    "        k22 = self._k(x2, x2)\n",
    "        k12 = self._k(x1, x2)\n",
    "\n",
    "        eta = k11 + k22 - 2 * k12\n",
    "\n",
    "        if eta > 0:\n",
    "            a2 = alpha2 + y2 * (e1 - e2) / eta\n",
    "            if a2 <= L:\n",
    "                a2 = L\n",
    "            elif a2 >= H:\n",
    "                a2 = H\n",
    "        # TODO: the negative case\n",
    "        else:\n",
    "            print(f\"[DEBUG] smo_step: eta = {eta}\")\n",
    "            \n",
    "            f1 = (y1*(e1 + self._b)) - (alpha1 * k11) - (s*alpha2*k12)\n",
    "            f2 = (y2*(e2 + self._b)) - (s*alpha1*k12) - (alpha2*k22)\n",
    "            L1 = alpha1 + s*(alpha2 - L)\n",
    "            H1 = alpha1 + s*(alpha2 - H)\n",
    "            \n",
    "            Lobj = (L1*f1) + (L*f2) + (0.5*(L1**2)*k11) + (0.5*(L**2)*k22) + (s*L*L1*k12)\n",
    "            Hobj = (H1*f1) + (H*f2) + (0.5*(H1**2)*k11) + (0.5*(H**2)*k22) + (s*H*H1*k12)\n",
    "            \n",
    "            if (Lobj < Hobj- self.eps):\n",
    "                a2 = L\n",
    "            elif (Lobj > (Hobj + self.eps)):\n",
    "                  a2 = H\n",
    "            else:\n",
    "                  a2 = alpha2\n",
    "            \n",
    "        if np.abs(a2 - alpha2) < 1e-3 * (a2 + alpha2 + 1e-3):\n",
    "            return 0\n",
    "\n",
    "        a1 = alpha1 + s * (alpha2 - a2)\n",
    "\n",
    "        # Update threshold to reflect change in Lagrange multipliers\n",
    "        b1 = e1 + y1 * (a1 - alpha1) * k11 + y2 * (a2 - alpha2) * k12 + self._b\n",
    "        b2 = e2 + y1 * (a1 - alpha1) * k12 + y2 * (a2 - alpha2) * k22 + self._b\n",
    "        self._b = (b1 + b2) / 2\n",
    "\n",
    "        # Update weight vector to reflect change in a1 & a2, if SVM is linear\n",
    "        if self._kernel == 'linear':\n",
    "            self._weights = np.sum((self._targets * self._alphas)[:, None] * self._data, axis=0)\n",
    "        \n",
    "        # Store a1 and a2 in alpha array\n",
    "        self._alphas[i1] = a1\n",
    "        self._alphas[i2] = a2\n",
    "\n",
    "        # update error cache using new multipliers\n",
    "        for i in range (self._data.shape[0]):\n",
    "            self._error_cache[i] = self.predict_score(self._data[i]) - self._targets[i]\n",
    "\n",
    "        return 1\n",
    "\n",
    "    def examine(self, i2):\n",
    "        x2 = self._data[i2]\n",
    "        y2 = self._targets[i2]\n",
    "        alpha2 = self._alphas[i2]\n",
    "        e2 = self.predict_score(x2) - y2\n",
    "        r2 = e2 * y2\n",
    "\n",
    "        # Heuristic for picking the first multiplier\n",
    "        if (r2 < -self._tol and alpha2 < self._c) or (r2 > self._tol and alpha2 > 0):\n",
    "            f_idxs = np.where((self._alphas != 0) & (self._alphas != self._c))[0]\n",
    "\n",
    "            if len(f_idxs) > 1:\n",
    "                # Hueristic for second multiplier: get i1 with lowest absolute error |e1 - e2|\n",
    "\n",
    "                # TODO: Clean this up\n",
    "                if e2 > 0:\n",
    "                    min_error = 999999\n",
    "                    for i, v in enumerate(f_idxs):\n",
    "                        if v == i2:\n",
    "                            continue\n",
    "\n",
    "                        if self._error_cache[v] == 0:\n",
    "                            self._error_cache[v] = self.predict_score(self._data[v]) - self._targets[v]\n",
    "                        error = np.abs(e2 - self._error_cache[v])\n",
    "\n",
    "                        if error < min_error:\n",
    "                            min_error = error\n",
    "                            i1 = v\n",
    "                else:\n",
    "                    max_error = -999999\n",
    "                    for i, v in enumerate(f_idxs):\n",
    "                        if v == i2:\n",
    "                            continue\n",
    "\n",
    "                        if self._error_cache[v] == 0:\n",
    "                            self._error_cache[v] = self.predict_score(self._data[v]) - self._targets[v]\n",
    "                        error = np.abs(e2 - self._error_cache[v])\n",
    "\n",
    "                        if error > max_error:\n",
    "                            max_error = error\n",
    "                            i1 = v\n",
    "\n",
    "                if self.smo_step(i1, i2):\n",
    "                    return 1\n",
    "                \n",
    "                # Loop over all non-zero and non-C alpha, starting at random point\n",
    "                for i, v in enumerate(np.random.permutation(f_idxs)):\n",
    "                    if self.smo_step(v, i2):\n",
    "                        return 1\n",
    "                \n",
    "                # Loop over all possible i1, starting at a random point\n",
    "                for i in range(self._data.shape[0]):\n",
    "                    if i == i2:\n",
    "                        continue\n",
    "                    if self.smo_step(i, i2):\n",
    "                        return 1\n",
    "                \n",
    "        return 0\n",
    "    \n",
    "    def fit(self, data, targets):\n",
    "        self._data = data\n",
    "        self._targets = targets\n",
    "        \n",
    "        self._init_params()\n",
    "        \n",
    "        n_changed = 0\n",
    "        examine_all = True\n",
    "        n_iter = 0\n",
    "        \n",
    "        while (n_changed > 0 or examine_all is True) and n_iter < self._maxiter:\n",
    "            n_changed = 0\n",
    "            n_iter += 1\n",
    "            \n",
    "            if examine_all is True:\n",
    "                # loop over all training examples\n",
    "                for i in range(data.shape[0]):\n",
    "                    n_changed += self.examine(i)\n",
    "            else:\n",
    "                # loop over examples where alpha is not 0 & not C\n",
    "                f_idxs = np.where((self._alphas != 0) & (self._alphas != self._c))[0]\n",
    "                for i, v in enumerate(f_idxs):\n",
    "                    n_changed += self.examine(v)\n",
    "            \n",
    "            if examine_all is True:\n",
    "                examine_all = False\n",
    "            elif n_changed == 0:\n",
    "                examine_all = True\n",
    "    \n",
    "    def acc(self, y_pred,y):\n",
    "        y_pred = [1 if pred == -1. else 0 for pred in y_pred]\n",
    "        \n",
    "        accuracy = np.sum(y == y_pred)/len(y)\n",
    "        \n",
    "        return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a77091a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = datasets.load_iris()\n",
    "\n",
    "X = data.data\n",
    "y = data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae9aca6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 42, test_size = 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b975f81d",
   "metadata": {},
   "source": [
    "# Multi - class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d2a4216",
   "metadata": {},
   "source": [
    "## Model 1: Type 0 vs (Type 1 and Type 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1dac7698",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1]\n"
     ]
    }
   ],
   "source": [
    "# Redefine y for model 1\n",
    "y_for_model1 = []\n",
    "\n",
    "for i in range(len(y)):\n",
    "    if(y[i] != 0):\n",
    "        y_for_model1.append(1)\n",
    "    else:\n",
    "        y_for_model1.append(0)\n",
    "y_for_model1 = np.array(y_for_model1)\n",
    "print(y_for_model1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2f27fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train_m1, X_test_m1, y_train_m1, y_test_m1 = train_test_split(X, y_for_model1, random_state = 42, test_size=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f738ce37",
   "metadata": {},
   "source": [
    "## Linear Kernel "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0936f3d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] smo_step: eta = 0.0\n",
      "[41.37329759 18.74931904 28.31130831  8.37465952]\n",
      "331.87737160435535\n",
      "Accuracy of linear svm model 1=  13.333333333333334 %\n"
     ]
    }
   ],
   "source": [
    "#Model 1 creation my model\n",
    "l_svm_m1 = multiclass_svm(c =5.0)\n",
    "\n",
    "#Model 1 training and testing\n",
    "l_svm_m1.fit(X_train_m1, y_train_m1)\n",
    "print(l_svm_m1._weights)\n",
    "print(l_svm_m1._b)\n",
    "\n",
    "\n",
    "pred_m1_svm = l_svm_m1.predict(X_test_m1)\n",
    "print(\"Accuracy of linear svm model 1= \", (l_svm_m1.acc(pred_m1_svm, y_test_m1))*100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "52211646",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coef_=[[-0.18423713 -0.45122995  0.80794366  0.45071881]]\n",
      "intercept=[-0.10956519]\n",
      "Accuracy of linear svc model 1=  100.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "\n",
    "l_sk_model1 = LinearSVC()\n",
    "\n",
    "l_sk_model1.fit(X_train_m1, y_train_m1.astype(np.int32))\n",
    "\n",
    "print(f\"coef_={l_sk_model1.coef_}\")\n",
    "print(f\"intercept={l_sk_model1.intercept_}\")\n",
    "pred_m1_svc = l_sk_model1.predict(X_test_m1)\n",
    "print(\"Accuracy of linear svc model 1= \", accuracy_score(y_test_m1, pred_m1_svc)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1116312",
   "metadata": {},
   "source": [
    "## Poly Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4b941547",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13904.215100000001\n",
      "Accuracy of poly svm model 1=  0.0 %\n"
     ]
    }
   ],
   "source": [
    "p_svm_m1 = multiclass_svm(kernel = 'poly')\n",
    "\n",
    "#Model 1 training and testing\n",
    "p_svm_m1.fit(X_train_m1, y_train_m1)\n",
    "print(p_svm_m1._b)\n",
    "\n",
    "\n",
    "pred_m1_svm = p_svm_m1.predict(X_test_m1)\n",
    "print(\"Accuracy of poly svm model 1= \", (p_svm_m1.acc(pred_m1_svm, y_test_m1))*100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "123693a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intercept=[-1.25416081]\n",
      "Accuracy of poly svc model 1 =  100.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "p_svc_m1 = SVC(kernel = 'poly', degree = 2)\n",
    "p_svc_m1.fit(X_train_m1, y_train_m1.astype(np.int32))\n",
    "\n",
    "#print(f\"coef_={p_svc.coef_}\")\n",
    "print(f\"intercept={p_svc_m1.intercept_}\")\n",
    "\n",
    "pred_m1_svc = p_svc_m1.predict(X_test_m1)\n",
    "print(\"Accuracy of poly svc model 1 = \", accuracy_score(y_test_m1, pred_m1_svc)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2f32f18",
   "metadata": {},
   "source": [
    "## Model 2: Type 1 vs (Type 0 and Type 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0b2c55a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1]\n"
     ]
    }
   ],
   "source": [
    "# Redefine y for model 2\n",
    "y_for_model2 = []\n",
    "\n",
    "for i in range(len(y)):\n",
    "    if(y[i] != 1):\n",
    "        y_for_model2.append(1)\n",
    "    else:\n",
    "        y_for_model2.append(0)\n",
    "y_for_model2 = np.array(y_for_model2)\n",
    "print(y_for_model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5818ae87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train_m2, X_test_m2, y_train_m2, y_test_m2 = train_test_split(X, y_for_model2, random_state = 42, test_size=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4625ba83",
   "metadata": {},
   "source": [
    "## Linear Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4c040699",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] smo_step: eta = 0.0\n",
      "[DEBUG] smo_step: eta = 0.0\n",
      "[DEBUG] smo_step: eta = 0.0\n",
      "[DEBUG] smo_step: eta = 0.0\n",
      "[DEBUG] smo_step: eta = 0.0\n",
      "[1286.16  824.06  534.26  138.24]\n",
      "13158.036500000002\n",
      "Accuracy of linear svm model 2=  46.666666666666664 %\n"
     ]
    }
   ],
   "source": [
    "#Model 2 creation my model\n",
    "l_svm_m2 = multiclass_svm(c =5.0)\n",
    "\n",
    "#Model 2 training and testing\n",
    "l_svm_m2.fit(X_train_m2, y_train_m2)\n",
    "print(l_svm_m2._weights)\n",
    "print(l_svm_m2._b)\n",
    "\n",
    "\n",
    "pred_m2_svm = l_svm_m2.predict(X_test_m2)\n",
    "print(\"Accuracy of linear svm model 2= \", (l_svm_m2.acc(pred_m2_svm, y_test_m2))*100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f97a205c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coef_=[[-0.08289923  0.86696848 -0.38737716  0.95124133]]\n",
      "intercept=[-1.48721473]\n",
      "Accuracy of linear svc model 1=  73.33333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aadit\\anaconda3\\envs\\cse6363\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "l_sk_model2 = LinearSVC()\n",
    "\n",
    "l_sk_model2.fit(X_train_m2, y_train_m2.astype(np.int32))\n",
    "\n",
    "print(f\"coef_={l_sk_model2.coef_}\")\n",
    "print(f\"intercept={l_sk_model2.intercept_}\")\n",
    "pred_m2_svc = l_sk_model2.predict(X_test_m2)\n",
    "print(\"Accuracy of linear svc model 1= \", accuracy_score(y_test_m2, pred_m2_svc)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46e3e99d",
   "metadata": {},
   "source": [
    "## Poly Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9100f4e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] smo_step: eta = 0.0\n",
      "138580.82085000013\n",
      "Accuracy of poly svm model 2=  46.666666666666664 %\n"
     ]
    }
   ],
   "source": [
    "p_svm_m2 = multiclass_svm(kernel = 'poly')\n",
    "\n",
    "#Model 2 training and testing\n",
    "p_svm_m2.fit(X_train_m2, y_train_m2)\n",
    "print(p_svm_m2._b)\n",
    "\n",
    "\n",
    "pred_m2_svm = p_svm_m2.predict(X_test_m2)\n",
    "print(\"Accuracy of poly svm model 2= \", (p_svm_m2.acc(pred_m2_svm, y_test_m2))*100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "75bd70ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intercept=[-0.6704262]\n",
      "Accuracy of poly svc model 2 =  93.33333333333333\n"
     ]
    }
   ],
   "source": [
    "p_svc_m2 = SVC(kernel = 'poly', degree = 2)\n",
    "p_svc_m2.fit(X_train_m2, y_train_m2.astype(np.int32))\n",
    "\n",
    "#print(f\"coef_={p_svc.coef_}\")\n",
    "print(f\"intercept={p_svc_m2.intercept_}\")\n",
    "\n",
    "pred_m2_svc = p_svc_m2.predict(X_test_m2)\n",
    "print(\"Accuracy of poly svc model 2 = \", accuracy_score(y_test_m2, pred_m2_svc)*100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "765c7dc6",
   "metadata": {},
   "source": [
    "## Model 3: Type 2 vs (Type 0 and Type 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8db835fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0]\n"
     ]
    }
   ],
   "source": [
    "# Redefine y for model 3\n",
    "y_for_model3 = []\n",
    "\n",
    "for i in range(len(y)):\n",
    "    if(y[i] != 2):\n",
    "        y_for_model3.append(1)\n",
    "    else:\n",
    "        y_for_model3.append(0)\n",
    "y_for_model3 = np.array(y_for_model3)\n",
    "print(y_for_model3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4ceae74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train_m3, X_test_m3, y_train_m3, y_test_m3 = train_test_split(X, y_for_model3, random_state = 42, test_size=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6992aad0",
   "metadata": {},
   "source": [
    "## Linear Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "add8e06c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2395.36 1364.68 1255.55  345.35]\n",
      "28946.086000000003\n",
      "Accuracy of linear svm model 3=  86.66666666666667 %\n"
     ]
    }
   ],
   "source": [
    "#Model 3 creation my model\n",
    "l_svm_m3 = multiclass_svm(c =5.0)\n",
    "\n",
    "#Model 3 training and testing\n",
    "l_svm_m3.fit(X_train_m3, y_train_m3)\n",
    "print(l_svm_m3._weights)\n",
    "print(l_svm_m3._b)\n",
    "\n",
    "\n",
    "pred_m3_svm = l_svm_m3.predict(X_test_m3)\n",
    "print(\"Accuracy of linear svm model 3= \", (l_svm_m3.acc(pred_m3_svm, y_test_m3))*100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c516c7f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coef_=[[ 0.7414038   1.14194142 -1.36903246 -1.6526887 ]]\n",
      "intercept=[1.53419638]\n",
      "Accuracy of linear svc model 1=  100.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aadit\\anaconda3\\envs\\cse6363\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "l_sk_model3 = LinearSVC()\n",
    "\n",
    "l_sk_model3.fit(X_train_m3, y_train_m3.astype(np.int32))\n",
    "\n",
    "print(f\"coef_={l_sk_model3.coef_}\")\n",
    "print(f\"intercept={l_sk_model3.intercept_}\")\n",
    "pred_m3_svc = l_sk_model3.predict(X_test_m3)\n",
    "print(\"Accuracy of linear svc model 1= \", accuracy_score(y_test_m3, pred_m3_svc)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8048897",
   "metadata": {},
   "source": [
    "## Poly Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c2e8df86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "431269.76340000005\n",
      "Accuracy of poly svm model 3=  86.66666666666667 %\n"
     ]
    }
   ],
   "source": [
    "p_svm_m3 = multiclass_svm(kernel = 'poly')\n",
    "\n",
    "#Model 3 training and testing\n",
    "p_svm_m3.fit(X_train_m3, y_train_m3)\n",
    "print(p_svm_m3._b)\n",
    "\n",
    "\n",
    "pred_m3_svm = p_svm_m3.predict(X_test_m3)\n",
    "print(\"Accuracy of poly svm model 3= \", (p_svm_m3.acc(pred_m3_svm, y_test_m3))*100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b13389ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intercept=[3.21525098]\n",
      "Accuracy of poly svc model 3 =  100.0\n"
     ]
    }
   ],
   "source": [
    "p_svc_m3 = SVC(kernel = 'poly', degree = 2)\n",
    "p_svc_m3.fit(X_train_m3, y_train_m3.astype(np.int32))\n",
    "\n",
    "#print(f\"coef_={p_svc.coef_}\")\n",
    "print(f\"intercept={p_svc_m3.intercept_}\")\n",
    "\n",
    "pred_m3_svc = p_svc_m3.predict(X_test_m3)\n",
    "print(\"Accuracy of poly svc model 3 = \", accuracy_score(y_test_m3, pred_m3_svc)*100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (cse6363-ml)",
   "language": "python",
   "name": "cse6363-ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
